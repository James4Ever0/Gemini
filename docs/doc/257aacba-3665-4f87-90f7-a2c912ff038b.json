{
    "summary": "The code defines Transformer and Gemini models with multiple layers, handles different input types, and concatenates text with existing x for forward pass in the decoder, handling exceptions as needed.",
    "details": [
        {
            "comment": "The code defines a class for the Gemini model, which is an instance of the PyTorch Module. The model accepts arguments such as number of tokens, maximum sequence length, dimension, depth, etc., and utilizes various transformer-based components including Decoder and Transformer classes from gemini_torch package. It also includes several optional features like absolute position embedding and alibi position bias.",
            "location": "\"/media/root/Toshiba XG3/works/Gemini/docs/src/gemini_torch/model.py\":0-34",
            "content": "import torch\nfrom torch.nn import Module\nfrom zeta.structs import AutoregressiveWrapper\nfrom gemini_torch.transformer import Decoder, Transformer\nfrom gemini_torch.utils import ImageToTextEmbeddings, AudioToEmbeddings\ndef exists(val):\n    return val is not None\nclass Gemini(Module):\n    \"\"\"\n    Gemini model class.\n    Args:\n    - num_tokens: Number of tokens in the vocabulary\n    - max_seq_len: Maximum sequence length\n    - dim: Dimension of the model\n    - depth: Depth of the model\n    - dim_head: Dimension of the model head\n    - heads: Number of heads\n    - use_abs_pos_emb: Whether to use absolute position embedding\n    - alibi_pos_bias: Alibi position bias\n    - alibi_num_heads: Number of alibi heads\n    - rotary_xpos: Rotary position\n    - attn_flash: Attention flash\n    - deepnorm: Deep normalization\n    - shift_tokens: Number of tokens to shift\n    - attn_one_kv_head: Attention one key/value head\n    - qk_norm: Query-key normalization\n    - attn_qk_norm: Attention query-key normalization\n    - attn_qk_norm_dim_scale: Attention query-key normalization dimension scale"
        },
        {
            "comment": "This code initializes a Transformer model with specific parameters for the number of tokens, maximum sequence length, embedding provider, and various other attributes. It also includes options for absolute position embeddings, attention layers, and flash attention. The model is designed to handle text, image, or audio inputs, with options for patch size and audio sequence length.",
            "location": "\"/media/root/Toshiba XG3/works/Gemini/docs/src/gemini_torch/model.py\":35-74",
            "content": "    - embedding_provider: Embedding provider module\n    \"\"\"\n    def __init__(\n        self,\n        num_tokens=50432,\n        max_seq_len=32052,\n        dim=2560,\n        depth=32,\n        dim_head=128,\n        heads=24,\n        use_abs_pos_emb=False,\n        attn_flash=True,\n        attn_kv_heads=2,\n        qk_norm=True,\n        attn_qk_norm=True,\n        attn_qk_norm_dim_scale=True,\n        patches: int = 16,\n        patch_size: int = 16,\n        img_channels: int = 3,\n        audio_seq_len: int = 128,\n        *args,\n        **kwargs\n    ):\n        super().__init__()\n        try:\n            # Transformer model for the model\n            self.gemini = Transformer(\n                num_tokens=num_tokens,\n                max_seq_len=max_seq_len,\n                use_abs_pos_emb=use_abs_pos_emb,\n                attn_layers=Decoder(\n                    dim=dim,\n                    depth=depth,\n                    dim_head=dim_head,\n                    heads=heads,\n                    attn_flash=attn_flash,\n                    attn_kv_heads=attn_kv_heads,"
        },
        {
            "comment": "This code initializes a Gemini model with specified parameters and exceptions. The model consists of an autoregressive wrapper, image-to-text embedding layer, and audio-to-language embedding layer. The forward function is used for prediction.",
            "location": "\"/media/root/Toshiba XG3/works/Gemini/docs/src/gemini_torch/model.py\":75-102",
            "content": "                    qk_norm=qk_norm,\n                    attn_qk_norm=attn_qk_norm,\n                    attn_qk_norm_dim_scale=attn_qk_norm_dim_scale,\n                    *args,\n                    **kwargs\n                ),\n            )\n            # Autoregressive wrapper for the model\n            # self.decoder = AutoregressiveWrapper(self.gemini)\n            # Takes in imgs -> patches them -> transforms them to the same dimension as the model\n            self.img_to_text_embedding = ImageToTextEmbeddings(\n                patch_size=patches, dim=dim, seq_len=num_tokens, *args, **kwargs\n            )\n            # Takes in audio -> transforms it to the same dimension as the model\n            self.audio_to_lang_embedding = AudioToEmbeddings(\n                audio_seq_len=audio_seq_len, seqlen=max_seq_len, dim=dim, *args, **kwargs\n            )\n        except Exception as e:\n            print(\"Failed to initialize gemini: \", e)\n            raise e\n    def forward(\n        self,\n        text: torch.Tensor = None,"
        },
        {
            "comment": "This code defines a forward pass function for a model that takes in text, image, and audio inputs. It prints the shape of the text input, then processes the image and audio inputs if they exist. The code concatenates the embeddings of the text, image, and audio to produce the output.",
            "location": "\"/media/root/Toshiba XG3/works/Gemini/docs/src/gemini_torch/model.py\":103-139",
            "content": "        img: torch.Tensor = None,\n        audio: torch.Tensor = None,\n        *args,\n        **kwargs\n    ):\n        \"\"\"\n        Forward pass of the model.\n        Args:\n        - text: Text tensor\n        - img: Image tensor\n        Returns:\n        - torch.Tensor: The output of the model\n        Text input shape: [batch, seq_len, dim]\n        img input shape: [batch, channels, height, width]\n        audio input shape: [batch, audio_seq_len]\n        Output shape: [batch, seq_len, dim]\n        \"\"\"\n        print(f\"Text shape: {text.shape}\")\n        try:\n            if exists(img) and exists(audio):\n                # Process audio and image inputs\n                audio_emb = self.audio_to_lang_embedding(audio)\n                img_emb = self.img_to_transformer(img)\n                # Concatenate text, image, and audio embeddings\n                x = torch.cat((text, img_emb, audio_emb))\n            if exists(img):\n                # Process image input\n                x = self.img_to_text_embedding(img)\n                print(f\"Image shape: {x.shape}\")"
        },
        {
            "comment": "The code concatenates the text and the existing x, prints its shape, then returns it. If no exception occurs, it calls the decoder's forward method with the padded x as input. An exception will cause a failure message to print before re-raising the error.",
            "location": "\"/media/root/Toshiba XG3/works/Gemini/docs/src/gemini_torch/model.py\":140-150",
            "content": "                x = torch.cat((text, x))\n                print(f\"Concat shape: {x.shape}\")\n                return x\n            else:\n                x = text\n            # Call the forward method of the decoder once\n            return self.decoder(x, padded_x=x)\n        except Exception as e:\n            print(\"Failed in forward method: \", e)\n            raise"
        }
    ]
}